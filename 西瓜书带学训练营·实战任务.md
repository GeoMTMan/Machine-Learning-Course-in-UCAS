<a name="content">目录</a>

[西瓜书带学训练营·实战任务](#title)
- [1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用](#sklearn-lr)
	- [1.1. 任务描述](#sklearn-lr-task-description)
	- [1.2. 编程实现](#sklearn-lr-code)
	- [1.3. sklearn包中logistic算法的使用](#sklearn-lr-usage)
- [2. sklearn包中决策树算法类库的使用](#sklearn-decision-tree)
	- [2.1. DecisionTreeClassifier实例](#sklearn-decision-tree-decisiontreeclassifier-example)
	- [2.2. 可视化决策树](#sklearn-decision-tree-visualize)



<h1 name="title">西瓜书带学训练营·实战任务</h1>

<a name="sklearn-lr"><h2>1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用 [<sup>目录</sup>](#content)</h2></a>

<a name="sklearn-lr-task-description"><h3>1.1. 任务描述 [<sup>目录</sup>](#content)</h3></a>

具体任务可以到 ['达观杯'文本智能处理挑战赛官网](http://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E8%B5%9B%E4%BD%93%E4%B8%8E%E6%95%B0%E6%8D%AE.html) 查看

**任务**：建立模型通过长文本数据正文(article)，预测文本对应的类别(class)

数据：

> 数据包含2个csv文件：
> 
> - **train_set.csv**
> 
> 	此数据集用于训练模型，每一行对应一篇文章。文章分别在“字”和“词”的级别上做了脱敏处理。共有四列：
> 
> 	第一列是文章的索引(id)，第二列是文章正文在“字”级别上的表示，即字符相隔正文(article)；第三列是在“词”级别上的表示，即词语相隔正文(word_seg)；第四列是这篇文章的标注(class)。
> 
> 	注：每一个数字对应一个“字”，或“词”，或“标点符号”。“字”的编号与“词”的编号是独立的！
> 
> - **test_set.csv** 
> 
> 	此数据用于测试。数据格式同train_set.csv，但不包含class
> 	
> 	注：test_set与train_test中文章id的编号是独立的。

<a name="sklearn-lr-code"><h3>1.2. 编程实现 [<sup>目录</sup>](#content)</h3></a>

使用**logistic回归**来实现这个多元分类任务

```
import pandas as pd
from sklearn.feature_extract.txt import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.linear_model import LogisticRegression
from sklearn.model_select import train_test_split
from sklearn.externals import joblib
import time

t_start = time.time()

# ===========================================================
# 1. 载人数据与数据预处理
df_train = pd.read_csv('data/train_set.csv')
df_train = df_train.drop(columns='article',inplace=True)
df_test = pd.read_csv('data/test_set.csv')
df_test = df_test.drop(columns='article',inplace=True)
y_train = (df_train['class'] - 1).values


# ===========================================================
# 2. 特征工程，这里先使用经典的文本特征提取方法TFIDF，提取的TFIDF特征
vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, sublinear_tf=True)
vectorizer.fit(df_train['word_seg'])
X_train = vectorizer.transform(df_train['word_seg'])
X_test = vectorizer.transform(df_test['word_seg'])

# 可以将得到的TFIDF特征保存至本地
'''
data = (X_train,y_train,X_test)
f = open('data/data_tfidf.pkl','wb')
pickle.dump(data,f)
f.close()
'''


# ===========================================================
# 3. 特征降维，将上一步提取的TFIDF特征使用lsa方法进行特征降维
lsa = TruncatedSVD(n_components=200)
X_train = lsa.transform(X_train)
X_test = lsa.transform(X_test)


# ===========================================================
# 4. 训练分类器

# 划分训练集和验证集
X_train,X_vali,y_train,y_vali = train_test_split(X_train,y_train,test_size=0.1,random_state=0)

##  multi_class:分类方式选择参数，有"ovr(默认)"和"multinomial"两个值可选择，在二元逻辑回归中无区别
##  solver:优化算法选择参数，当penalty为"l1"时，参数只能是"liblinear(坐标轴下降法)"；"lbfgs"和"cg"都是关于目标函数的二阶泰勒展开
##  当penalty为"l2"时，参数可以是"lbfgs(拟牛顿法)","newton_cg(牛顿法变种)","seg(minibactch随机平均梯度下降)"
lr = LogisticRegression(multi_class="ovr",penalty="l2",solver="lbfgs")
lr.fit(X_train,y_train)

# 模型的保存与持久化
joblib.dump(lr,"logistic_lr.model")
joblib.load("logistic_lr.model") #加载模型,会保存该model文件


# ===========================================================
# 5. 在验证集上评估模型
pre_vali = lr.predict(X_vali)
pre_score = f1_score(y_true=y_vali,y_pred=pre_vali,average='macro')
print("验证集分数：{}".format(score_vali))


# ===========================================================
# 6. 对测试集进行预测
y_test = lr.predict(X_test) + 1
```

<a name="sklearn-lr-usage"><h3>1.3. sklearn包中logistic算法的使用 [<sup>目录</sup>](#content)</h3></a>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-1.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-2.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-3.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-4.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-5.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-6.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-7.png width=800 /></p>

<a name="sklearn-decision-tree"><h2>2. sklearn包中决策树算法类库的使用 [<sup>目录</sup>](#content)</h2></a>

<a name="sklearn-decision-tree-decisiontreeclassifier-example"><h3>2.1. DecisionTreeClassifier实例 [<sup>目录</sup>](#content)</h3></a>

```
from itertools import product

import numpy as np
import matplotlib.pyplot as plt

from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier


# 使用自带的iris数据
iris = datasets.load_iris()
X = iris.data[:, [0, 2]]
y = iris.target

# 训练模型，限制树的最大深度4
clf = DecisionTreeClassifier(max_depth=4)
#拟合模型
clf.fit(X, y)


# 画图
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                     np.arange(y_min, y_max, 0.1))

Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.4)
plt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.8)
plt.show()
```

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-decision-tree-1.png width=800 /></p>

<a name="sklearn-decision-tree-visualize"><h3>2.2. 可视化决策树 [<sup>目录</sup>](#content)</h3></a>

scikit-learn中决策树的可视化一般需要安装graphviz，主要包括graphviz的安装和python的graphviz插件的安装

> - 1) 安装graphviz。下载地址在：`http://www.graphviz.org`/。如果你是linux，可以用apt-get或者yum的方法安装。如果是windows，就在官网下载msi文件安装。无论是linux还是windows，装完后都要设置环境变量，将graphviz的bin目录加到PATH，比如我是windows，将`C:/Program Files (x86)/Graphviz2.38/bin/`加入了`PATH`
> 
> - 2) 安装python插件graphviz： `pip install graphviz`
> 
> 
> - 3) 安装python插件pydotplus: `pip install pydotplus`

这样环境就搭好了，有时候python会很笨，仍然找不到graphviz，这时，可以在代码里面加入这一行：

```
os.environ["PATH"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'
```

可视化决策树的代码：

```
from IPython.display import Image  
from sklearn import tree
import pydotplus 
dot_data = tree.export_graphviz(clf, out_file=None, 
                         feature_names=iris.feature_names,  
                         class_names=iris.target_names,  
                         filled=True, rounded=True,  
                         special_characters=True)  
graph = pydotplus.graph_from_dot_data(dot_data)  
Image(graph.create_png())
```

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-decision-tree-2.png width=800 /></p>


---

参考资料：

(1) [【GitHub】MLjian/TextClassificationImplement](https://github.com/MLjian/TextClassificationImplement)

(2) [刘建平Pinard《scikit-learn 逻辑回归类库使用小结》](https://www.cnblogs.com/pinard/p/6035872.html)

(3) [机器学习sklearn19.0——Logistic回归算法](https://blog.csdn.net/loveliuzz/article/details/78708359)

(4) [刘建平Pinard《scikit-learn决策树算法类库使用小结》](https://www.cnblogs.com/pinard/p/6056319.html)
