<a name="content">目录</a>

[西瓜书带学训练营·实战任务](#title)
- [1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用](#sklearn-lr)
	- [1.1. 任务描述](#sklearn-lr-task-description)
	- [1.2. 编程实现](#sklearn-lr-code)
	- [1.3. sklearn包中logistic算法的使用](#sklearn-lr-usage)




<h1 name="title">西瓜书带学训练营·实战任务</h1>

<a name="sklearn-lr"><h2>1. “达观杯”文本智能处理挑战赛：sklearn包中logistic算法的使用 [<sup>目录</sup>](#content)</h2></a>

<a name="sklearn-lr-task-description"><h3>1.1. 任务描述 [<sup>目录</sup>](#content)</h3></a>

具体任务可以到 ['达观杯'文本智能处理挑战赛官网](http://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E8%B5%9B%E4%BD%93%E4%B8%8E%E6%95%B0%E6%8D%AE.html) 查看

**任务**：建立模型通过长文本数据正文(article)，预测文本对应的类别(class)

数据：

> 数据包含2个csv文件：
> 
> - **train_set.csv**
> 
> 	此数据集用于训练模型，每一行对应一篇文章。文章分别在“字”和“词”的级别上做了脱敏处理。共有四列：
> 
> 	第一列是文章的索引(id)，第二列是文章正文在“字”级别上的表示，即字符相隔正文(article)；第三列是在“词”级别上的表示，即词语相隔正文(word_seg)；第四列是这篇文章的标注(class)。
> 
> 	注：每一个数字对应一个“字”，或“词”，或“标点符号”。“字”的编号与“词”的编号是独立的！
> 
> - **test_set.csv** 
> 
> 	此数据用于测试。数据格式同train_set.csv，但不包含class
> 	
> 	注：test_set与train_test中文章id的编号是独立的。

<a name="sklearn-lr-code"><h3>1.2. 编程实现 [<sup>目录</sup>](#content)</h3></a>

使用**logistic回归**来实现这个多元分类任务

```
import pandas as pd
from sklearn.feature_extract.txt import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.linear_model import LogisticRegression
from sklearn.model_select import train_test_split
from sklearn.externals import joblib
import time

t_start = time.time()

# ===========================================================
# 1. 载人数据与数据预处理
df_train = pd.read_csv('data/train_set.csv')
df_train = df_train.drop(columns='article',inplace=True)
df_test = pd.read_csv('data/test_set.csv')
df_test = df_test.drop(columns='article',inplace=True)
y_train = (df_train['class'] - 1).values


# ===========================================================
# 2. 特征工程，这里先使用经典的文本特征提取方法TFIDF，提取的TFIDF特征
vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=3, max_df=0.9, sublinear_tf=True)
vectorizer.fit(df_train['word_seg'])
X_train = vectorizer.transform(df_train['word_seg'])
X_test = vectorizer.transform(df_test['word_seg'])

# 可以将得到的TFIDF特征保存至本地
'''
data = (X_train,y_train,X_test)
f = open('data/data_tfidf.pkl','wb')
pickle.dump(data,f)
f.close()
'''


# ===========================================================
# 3. 特征降维，将上一步提取的TFIDF特征使用lsa方法进行特征降维
lsa = TruncatedSVD(n_components=200)
X_train = lsa.transform(X_train)
X_test = lsa.transform(X_test)


# ===========================================================
# 4. 训练分类器

# 划分训练集和验证集
X_train,X_vali,y_train,y_vali = train_test_split(X_train,y_train,test_size=0.1,random_state=0)

##  multi_class:分类方式选择参数，有"ovr(默认)"和"multinomial"两个值可选择，在二元逻辑回归中无区别
##  solver:优化算法选择参数，当penalty为"l1"时，参数只能是"liblinear(坐标轴下降法)"；"lbfgs"和"cg"都是关于目标函数的二阶泰勒展开
##  当penalty为"l2"时，参数可以是"lbfgs(拟牛顿法)","newton_cg(牛顿法变种)","seg(minibactch随机平均梯度下降)"
lr = LogisticRegression(multi_class="ovr",penalty="l2",solver="lbfgs")
lr.fit(X_train,y_train)

# 模型的保存与持久化
joblib.dump(lr,"logistic_lr.model")
joblib.load("logistic_lr.model") #加载模型,会保存该model文件


# ===========================================================
# 5. 在验证集上评估模型
pre_vali = lr.predict(X_vali)
pre_score = f1_score(y_true=y_vali,y_pred=pre_vali,average='macro')
print("验证集分数：{}".format(score_vali))


# ===========================================================
# 6. 对测试集进行预测
y_test = lr.predict(X_test) + 1
```

<a name="sklearn-lr-usage"><h3>1.3. sklearn包中logistic算法的使用 [<sup>目录</sup>](#content)</h3></a>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-1.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-2.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-3.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-4.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-5.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-6.png width=800 /></p>

<p align="center"><img src=./picture/InAction-MachineLearning-XGS-sklearn-lr-7.png width=800 /></p>




---

参考资料：

(1) [【GitHub】MLjian/TextClassificationImplement](https://github.com/MLjian/TextClassificationImplement)

(2) [机器学习sklearn19.0——Logistic回归算法](https://blog.csdn.net/loveliuzz/article/details/78708359)
